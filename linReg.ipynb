{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import count, isnan, col, when,mean\n",
    "spark=SparkSession.builder.appName('RegressionWithPySpark').getOrCreate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explore and Defining Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[CRIM: double, ZN: double, INDUS: double, CHAS: int, NOX: double, RM: double, AGE: double, DIS: double, RAD: int, TAX: int, PTRATIO: double, B: double, LSTAT: double, MEDV: double]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import dataset\n",
    "df=spark.read.format('csv') \\\n",
    ".option('inferSchema','true') \\\n",
    ".option('header','true') \\\n",
    ".option('sep',',') \\\n",
    ".load('data.csv')\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CRIM',\n",
       " 'ZN',\n",
       " 'INDUS',\n",
       " 'CHAS',\n",
       " 'NOX',\n",
       " 'RM',\n",
       " 'AGE',\n",
       " 'DIS',\n",
       " 'RAD',\n",
       " 'TAX',\n",
       " 'PTRATIO',\n",
       " 'B',\n",
       " 'LSTAT',\n",
       " 'MEDV']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CRIM per capita crime rate by town\n",
    "\n",
    "ZN proportion of residential land zoned for lots over\n",
    "25,000 sq.ft.\n",
    "\n",
    "INDUS proportion of non-retail business acres per town\n",
    "CHAS Charles River dummy variable (= 1 if tract bounds\n",
    "river; 0 otherwise)\n",
    "\n",
    "NOX nitric oxides concentration (parts per 10 million)\n",
    "\n",
    "RM average number of rooms per dwelling\n",
    "\n",
    "AGE proportion of owner-occupied units built prior to 1940\n",
    "\n",
    "DIS weighted distances to five Boston employment centres\n",
    "\n",
    "RAD index of accessibility to radial highways\n",
    "\n",
    "TAX full-value property-tax rate per $10,000\n",
    "\n",
    "PTRATIO pupil-teacher ratio by town\n",
    "\n",
    "B 1000(Bk - 0.63)^2 where Bk is the proportion of blacks\n",
    "by town\n",
    "\n",
    "LSTAT % lower status of the population\n",
    "\n",
    "MEDV Median value of owner-occupied homes in $1000's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511 14\n"
     ]
    }
   ],
   "source": [
    "print(df.count(),len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+-----------------+-------------------+-------------------+------------------+------------------+------------------+-----------------+------------------+------------------+-----------------+------------------+-----------------+\n",
      "|summary|             CRIM|                ZN|            INDUS|               CHAS|                NOX|                RM|               AGE|               DIS|              RAD|               TAX|           PTRATIO|                B|             LSTAT|             MEDV|\n",
      "+-------+-----------------+------------------+-----------------+-------------------+-------------------+------------------+------------------+------------------+-----------------+------------------+------------------+-----------------+------------------+-----------------+\n",
      "|  count|              511|               511|              511|                511|                511|               506|               511|               511|              511|               511|               511|              511|               511|              511|\n",
      "|   mean|3.584138577299414|11.252446183953033|11.15109589041098| 0.0684931506849315| 0.5547567514677099| 6.287588932806333| 68.61624266144817|3.7838759295499003|  9.4853228962818|  407.440313111546| 18.50000000000002|356.6009001956939|12.879549902152645|22.68219178082194|\n",
      "| stddev|8.564433333509855|23.234838381032183|6.828174588309389|0.25283777534076923|0.11530992214681592|0.7038016463619771|28.099130374719934|2.0986313624266293|8.688468797353902|167.90353164925963|2.2003475661278435|90.88267879563416| 7.797415936527356|9.484262294196041|\n",
      "|    min|          0.00632|               0.0|             0.46|                  0|              0.385|             3.561|               2.9|            1.1296|                1|               187|              12.6|             0.32|              1.73|              5.0|\n",
      "|    max|          88.9762|             100.0|            27.74|                  1|              0.871|              8.78|             100.0|           12.1265|               24|               711|              23.0|            396.9|              76.0|             67.0|\n",
      "+-------+-----------------+------------------+-----------------+-------------------+-------------------+------------------+------------------+------------------+-----------------+------------------+------------------+-----------------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+-----+----+---+---+---+---+---+---+-------+---+-----+----+\n",
      "|CRIM| ZN|INDUS|CHAS|NOX| RM|AGE|DIS|RAD|TAX|PTRATIO|  B|LSTAT|MEDV|\n",
      "+----+---+-----+----+---+---+---+---+---+---+-------+---+-----+----+\n",
      "|   0|  0|    0|   0|  0|  5|  0|  0|  0|  0|      0|  0|    0|   0|\n",
      "+----+---+-----+----+---+---+---+---+---+---+-------+---+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns] \\\n",
    "   ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_RM = df.select(mean(df['RM'])).collect()[0][0]\n",
    "\n",
    "df = df.fillna(mean_RM, subset=['RM'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make our target an output label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+----+-----+-----------------+-----+------+---+---+-------+------+-----+-----+\n",
      "|   CRIM|  ZN|INDUS|CHAS|  NOX|               RM|  AGE|   DIS|RAD|TAX|PTRATIO|     B|LSTAT|label|\n",
      "+-------+----+-----+----+-----+-----------------+-----+------+---+---+-------+------+-----+-----+\n",
      "|0.00632|18.0| 2.31|   0|0.538|            6.575| 65.2|  4.09|  1|296|   15.3| 396.9| 4.98| 24.0|\n",
      "|0.02731| 0.0| 7.07|   0|0.469|            6.421| 78.9|4.9671|  2|242|   17.8| 396.9| 9.14| 21.6|\n",
      "|0.02729| 0.0| 7.07|   0|0.469|            7.185| 61.1|4.9671|  2|242|   17.8|392.83| 4.03| 34.7|\n",
      "|0.03237| 0.0| 2.18|   0|0.458|            6.998| 45.8|6.0622|  3|222|   18.7|394.63| 2.94| 33.4|\n",
      "|0.06905| 0.0| 2.18|   0|0.458|            7.147| 54.2|6.0622|  3|222|   18.7| 396.9| 5.33| 36.2|\n",
      "|0.02985| 0.0| 2.18|   0|0.458|             6.43| 58.7|6.0622|  3|222|   18.7|394.12| 5.21| 28.7|\n",
      "|0.08829|12.5| 7.87|   0|0.524|            6.012| 66.6|5.5605|  5|311|   15.2| 395.6|12.43| 22.9|\n",
      "|0.14455|12.5| 7.87|   0|0.524|            6.172| 96.1|5.9505|  5|311|   15.2| 396.9|19.15| 27.1|\n",
      "|0.21124|12.5| 7.87|   0|0.524|            5.631|100.0|6.0821|  5|311|   15.2|386.63|29.93| 16.5|\n",
      "|0.17004|12.5| 7.87|   0|0.524|            6.004| 85.9|6.5921|  5|311|   15.2|386.71| 17.1| 18.9|\n",
      "|0.22489|12.5| 7.87|   0|0.524|6.287588932806333| 94.3|6.3467|  5|311|   15.2|392.52|20.45| 15.0|\n",
      "|0.11747|12.5| 7.87|   0|0.524|            6.009| 82.9|6.2267|  5|311|   15.2| 396.9|13.27| 18.9|\n",
      "|0.09378|12.5| 7.87|   0|0.524|            5.889| 39.0|5.4509|  5|311|   15.2| 390.5|15.71| 21.7|\n",
      "|0.62976| 0.0| 8.14|   0|0.538|            5.949| 61.8|4.7075|  4|307|   21.0| 396.9| 8.26| 20.4|\n",
      "|0.63796| 0.0| 8.14|   0|0.538|            6.096| 84.5|4.4619|  4|307|   21.0|380.02|10.26| 18.2|\n",
      "|0.62739| 0.0| 8.14|   0|0.538|            5.834| 56.5|4.4986|  4|307|   21.0|395.62| 8.47| 19.9|\n",
      "|1.05393| 0.0| 8.14|   0|0.538|            5.935| 29.3|4.4986|  4|307|   21.0|386.85| 6.58| 23.1|\n",
      "| 0.7842| 0.0| 8.14|   0|0.538|             5.99| 81.7|4.2579|  4|307|   21.0|386.75|14.67| 17.5|\n",
      "|0.80271| 0.0| 8.14|   0|0.538|            5.456| 36.6|3.7965|  4|307|   21.0|288.99|11.69| 20.2|\n",
      "| 0.7258| 0.0| 8.14|   0|0.538|            5.727| 69.5|3.7965|  4|307|   21.0|390.95|11.28| 18.2|\n",
      "+-------+----+-----+----+-----+-----------------+-----+------+---+---+-------+------+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=df.withColumnRenamed('MEDV','label')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|   corr(RM, label)|\n",
      "+------------------+\n",
      "|0.6669538165333394|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import corr\n",
    "\n",
    "#shows correlation\n",
    "df.select(corr('RM','label')).show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preparing Data with Feature Vector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CRIM: double (nullable = true)\n",
      " |-- ZN: double (nullable = true)\n",
      " |-- INDUS: double (nullable = true)\n",
      " |-- CHAS: integer (nullable = true)\n",
      " |-- NOX: double (nullable = true)\n",
      " |-- RM: double (nullable = false)\n",
      " |-- AGE: double (nullable = true)\n",
      " |-- DIS: double (nullable = true)\n",
      " |-- RAD: integer (nullable = true)\n",
      " |-- TAX: integer (nullable = true)\n",
      " |-- PTRATIO: double (nullable = true)\n",
      " |-- B: double (nullable = true)\n",
      " |-- LSTAT: double (nullable = true)\n",
      " |-- label: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.linalg import Vector\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# we are turning all of our features into a single vector\n",
    "vec_assembler = VectorAssembler(inputCols=['CRIM','ZN','INDUS', \\\n",
    "                'CHAS','NOX','AGE','RM','DIS','RAD','TAX',\n",
    "                'PTRATIO','B','LSTAT'],outputCol='features') \n",
    "\n",
    "# add it to the dataframe\n",
    "features_df = vec_assembler.transform(df)  \n",
    "#check if its added  \n",
    "features_df.printSchema()                                                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------+\n",
      "|features                                                                 |\n",
      "+-------------------------------------------------------------------------+\n",
      "|[0.00632,18.0,2.31,0.0,0.538,65.2,6.575,4.09,1.0,296.0,15.3,396.9,4.98]  |\n",
      "|[0.02731,0.0,7.07,0.0,0.469,78.9,6.421,4.9671,2.0,242.0,17.8,396.9,9.14] |\n",
      "|[0.02729,0.0,7.07,0.0,0.469,61.1,7.185,4.9671,2.0,242.0,17.8,392.83,4.03]|\n",
      "|[0.03237,0.0,2.18,0.0,0.458,45.8,6.998,6.0622,3.0,222.0,18.7,394.63,2.94]|\n",
      "|[0.06905,0.0,2.18,0.0,0.458,54.2,7.147,6.0622,3.0,222.0,18.7,396.9,5.33] |\n",
      "+-------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#check if its empty\n",
    "features_df.select('features').show(5,False) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building the Linear Regression Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[0.00632,18.0,2.3...| 24.0|\n",
      "|[0.02731,0.0,7.07...| 21.6|\n",
      "|[0.02729,0.0,7.07...| 34.7|\n",
      "|[0.03237,0.0,2.18...| 33.4|\n",
      "|[0.06905,0.0,2.18...| 36.2|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#create model with features and label\n",
    "model_df = features_df.select('features','label') \n",
    "model_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[0.00632,18.0,2.3...| 24.0|\n",
      "|[0.00906,90.0,2.9...| 32.2|\n",
      "|[0.01301,35.0,1.5...| 32.7|\n",
      "|[0.0136,75.0,4.0,...| 18.9|\n",
      "|[0.01381,80.0,0.4...| 50.0|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#split data into train and test dataframe\n",
    "train_df , test_df=model_df.randomSplit([0.75,0.25])\n",
    "\n",
    "train_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.14120652027475708,0.04182117142375692,0.0035851640066364206,3.5125410409130526,-14.98042589842389,-0.05954367804062648,6.97876671244456,-1.5052308374998848,0.1462364172729257,-0.01098632722063642,-0.7037160470715509,0.013534749338465137,0.018674676376903718]\n",
      "7.62647939272917\n",
      "0.6397562618042114\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "# Initializing Linear Regression \n",
    "lin_Reg = LinearRegression(labelCol='label',regParam=.01)\n",
    "\n",
    "# Fit our data to the model\n",
    "lr_model = lin_Reg.fit(train_df)\n",
    "\n",
    "# print slope coefficients and intercept for lin reg \n",
    "print(lr_model.coefficients)\n",
    "print(lr_model.intercept)\n",
    "\n",
    "#evaluate the model using r^2\n",
    "training_predictions = lr_model.evaluate(train_df)\n",
    "print(training_predictions.r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5450790719998915\n",
      "6.248837202908647\n"
     ]
    }
   ],
   "source": [
    "# evaluating model with unseen data \n",
    "test_results = lr_model.evaluate(test_df)\n",
    "print(test_results.r2)\n",
    "print(test_results.rootMeanSquaredError)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear Regression using Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "#split our data once again\n",
    "train_df, test_df, = df.randomSplit([.8,.2])\n",
    "\n",
    "#define the features\n",
    "features = ['CRIM',\n",
    " 'ZN',\n",
    " 'INDUS',\n",
    " 'CHAS',\n",
    " 'NOX',\n",
    " 'RM',\n",
    " 'AGE',\n",
    " 'DIS',\n",
    " 'RAD',\n",
    " 'TAX',\n",
    " 'PTRATIO',\n",
    " 'B',\n",
    " 'LSTAT',]\n",
    "\n",
    "# create out_features vector from all of our features\n",
    "stage_1 = VectorAssembler(inputCols=features, outputCol='out_features')\n",
    "# scale our features\n",
    "stage_2 = StandardScaler(inputCol='out_features',outputCol='features')\n",
    "# initalize linear regression \n",
    "stage_3 = LinearRegression()\n",
    "# define stages\n",
    "stages=[stage_1,stage_2,stage_3]\n",
    "\n",
    "#create our pipeline\n",
    "pipeline=Pipeline(stages=stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/08 11:06:14 WARN Instrumentation: [29ac18d4] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+----+-----+-----+----+-------+---+---+-------+------+-----+-----+--------------------+--------------------+------------------+\n",
      "|   CRIM|  ZN|INDUS|CHAS|  NOX|   RM| AGE|    DIS|RAD|TAX|PTRATIO|     B|LSTAT|label|        out_features|            features|        prediction|\n",
      "+-------+----+-----+----+-----+-----+----+-------+---+---+-------+------+-----+-----+--------------------+--------------------+------------------+\n",
      "|0.00632|18.0| 2.31|   0|0.538|6.575|65.2|   4.09|  1|296|   15.3| 396.9| 4.98| 24.0|[0.00632,18.0,2.3...|[7.36569883299710...| 27.92312329512297|\n",
      "|0.01096|55.0| 2.25|   0|0.389|6.453|31.9| 7.3073|  1|300|   15.3|394.72| 8.23| 22.0|[0.01096,55.0,2.2...|[0.00127734270901...|27.878213678840247|\n",
      "|0.01439|60.0| 2.93|   0|0.401|6.604|18.8| 6.2196|  1|265|   15.6| 376.7| 4.38| 29.1|[0.01439,60.0,2.9...|[0.00167709503491...| 31.38127280650602|\n",
      "|0.01709|90.0| 2.02|   0| 0.41|6.728|36.1|12.1265|  5|187|   17.0|384.46|  4.5| 30.1|[0.01709,90.0,2.0...|[0.00199176887746...|23.356082947935043|\n",
      "|0.02177|82.5| 2.03|   0|0.415| 7.61|15.7|   6.27|  2|348|   14.7|395.38| 3.11| 42.3|[0.02177,82.5,2.0...|[0.00253720353788...| 38.31323394001239|\n",
      "+-------+----+-----+----+-----+-----+----+-------+---+---+-------+------+-----+-----+--------------------+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit our data\n",
    "model = pipeline.fit(train_df)\n",
    "\n",
    "# adding prediction to our test df to see actual vs prediction\n",
    "pred_result = model.transform(test_df)\n",
    "pred_result.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6223355435411346\n",
      "6.142123443414813\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "#Initalizing Regression Evaluator\n",
    "regeval = RegressionEvaluator(labelCol='label',predictionCol='prediction',metricName='rmse')\n",
    "\n",
    "#evaluating our prediction\n",
    "acc = regeval.evaluate(pred_result,{regeval.metricName : 'r2'})\n",
    "print(acc)\n",
    "rmse = regeval.evaluate(pred_result)\n",
    "print(rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
